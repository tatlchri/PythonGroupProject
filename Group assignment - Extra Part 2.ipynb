{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "BS1819-1617  \n",
    "Data Structures and Algorithms  \n",
    "Group Assignment  \n",
    "</b>\n",
    "\n",
    "Team 3:  \n",
    "  * Ahmad Bilal Aslam  \n",
    "  * Chris Ying  \n",
    "  * Christina Lefkothea Tatli   \n",
    "  * Joh B  \n",
    "  * Kelvin Goh  \n",
    "  * Selly Salkha  \n",
    "\n",
    "\n",
    "<b><u> Part 4.2 (Extra part 2) </u></b>\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## PART ONE, PART TWO and EXTRA PART ONE code - to remove this when merging all the Jupyter notebooks together ##\n",
    "#################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "##### START OF PART 1 - calculate daily returns #####\n",
    "\n",
    "##~~ KEY VARIABLE: \"returns\" stores daily returns of stocks\n",
    "\n",
    "##### To Read company names into a dictionary\n",
    "def readNamesIntoDict():\n",
    "    d = dict()\n",
    "    input_file = csv.DictReader(open(\"SP_500_firms.csv\"))\n",
    "    for row in input_file:\n",
    "        #print(row)\n",
    "        d[row['Symbol']] = [row['Name'],row['Sector']]\n",
    "    return d\n",
    "\n",
    "##### To calculate daily returns from stock prices\n",
    "def returns_Stocks(priceData):      \n",
    "    # input is a pd.dataframe of stock prices\n",
    "    # output is a pd.dataframe of daily returns    \n",
    "    returns = priceData.pct_change()\n",
    "    # remove index 0 of returns - it's a nan value because the first period data has no daily return\n",
    "    #returns = returns[1:len(returns)]\n",
    "    # We had used the built-in function, the next function below is the manual calculation\n",
    "    return returns\n",
    "\n",
    "def returns_Stocks_manual_calc(priceData):      \n",
    "    # Manual calculation of the returns\n",
    "    returns = priceData / priceData.shift(1) - 1\n",
    "    # remove index 0 of returns - it's a nan value because the first period data has no daily return\n",
    "    #returns = returns[1:len(returns)]\n",
    "    return returns\n",
    "\n",
    "# make sure that the manual calculation is same as built-in function\n",
    "def test_returns_Stock_built_in_equals_manual(priceData):  \n",
    "    returns_built_in = returns_Stocks(priceData)\n",
    "    returns_manual = returns_Stocks_manual_calc(priceData)\n",
    "    difference = returns_built_in - returns_manual \n",
    "    print(\"The total difference between built-in and manual way of calculating daily returns, across stocks and time period, is:\", difference.sum().sum()) \n",
    "\n",
    "##### Several functions to determine which stock has max, min return; which are overall best, worst stocks; and max and min std of daily returns\n",
    "def max_return(returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of daily returns, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the maximum daily return along with company name and Sector\n",
    "    maxDaily_byComp  = returns.max()            #Maximum returns for each company\n",
    "\n",
    "    maxDaily = maxDaily_byComp.max()            #Overall highest daily return\n",
    "    maxDaily_CompSym = maxDaily_byComp.idxmax() #Getting index of the maximum return value\n",
    "\n",
    "    maxDaily_CompName = namesDict[maxDaily_CompSym][0]  #Company Name using its symbol\n",
    "    maxDaily_Sector = namesDict[maxDaily_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return maxDaily_Sector, maxDaily_CompName, maxDaily\n",
    "    \n",
    "\n",
    "def min_return (returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of daily returns, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the minimum daily return along with company name and Sector\n",
    "\n",
    "    minDaily_byComp  = returns.min()            #Minimum returns for each company\n",
    "\n",
    "    minDaily = minDaily_byComp.min()            #Overall lowest daily return\n",
    "    minDaily_CompSym = minDaily_byComp.idxmin() #Getting index of the minimum return value\n",
    "\n",
    "    minDaily_CompName = namesDict[minDaily_CompSym][0]  #Company Name using its symbol\n",
    "    minDaily_Sector = namesDict[minDaily_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return minDaily_Sector, minDaily_CompName, minDaily\n",
    "\n",
    "\n",
    "def overall_best (priceData, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the maximum yearly return along with company name and Sector\n",
    "    overallReturn_byComp  = priceData.iloc[-1] / priceData.iloc[0] - 1   #yearly returns for each company\n",
    "\n",
    "    overallBest = overallReturn_byComp.max()            #best yearly return\n",
    "    overallBest_CompSym = overallReturn_byComp.idxmax() #Getting index of the best yearly return\n",
    "\n",
    "     #Loading Company Symbols mapping into namesDict\n",
    "    overallBest_CompName = namesDict[overallBest_CompSym][0]  #Company Name using its symbol\n",
    "    overallBest_Sector = namesDict[overallBest_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return overallBest_Sector, overallBest_CompName, overallBest\n",
    "    \n",
    "\n",
    "def overall_worst (priceData, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the minimum yearly return along with company name and Sector\n",
    "    overallReturn_byComp  = priceData.iloc[-1] / priceData.iloc[0] - 1   #yearly returns for each company\n",
    "\n",
    "    overallWorst = overallReturn_byComp.min()            #worst yearly return\n",
    "    overallWorst_CompSym = overallReturn_byComp.idxmin() #Getting index of the worst yearly return\n",
    "\n",
    "    overallWorst_CompName = namesDict[overallWorst_CompSym][0]  #Company Name using its symbol\n",
    "    overallWorst_Sector = namesDict[overallWorst_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return overallWorst_Sector, overallWorst_CompName, overallWorst\n",
    "\n",
    "\n",
    "def max_std (returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the maximum std. dev along with company name and Sector\n",
    "    std_byComp  = returns.std()            #std. dev of returns for each company\n",
    "\n",
    "    maxStd = std_byComp.max()            #maximum std. dev\n",
    "    maxStd_CompSym = std_byComp.idxmax() #Getting index of the maximum std. dev\n",
    "\n",
    "    namesDict = readNamesIntoDict() #Loading Company Symbols mapping into namesDict\n",
    "    maxStd_CompName = namesDict[maxStd_CompSym][0]  #Company Name using its symbol\n",
    "    maxStd_Sector = namesDict[maxStd_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return maxStd_Sector, maxStd_CompName, maxStd\n",
    "    \n",
    "    \n",
    "def min_std (returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the minimum std. dev along with company name and Sector\n",
    "    std_byComp  = returns.std()            #std. dev of returns for each company\n",
    "\n",
    "    minStd = std_byComp.min()            #minimum std. dev\n",
    "    minStd_CompSym = std_byComp.idxmin() #Getting index of the minimum std. dev\n",
    "\n",
    "    minStd_CompName = namesDict[minStd_CompSym][0]  #Company Name using its symbol\n",
    "    minStd_Sector = namesDict[minStd_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return minStd_Sector, minStd_CompName, minStd\n",
    "\n",
    "\n",
    "##### Read company names into a dictionary\n",
    "namesDict = readNamesIntoDict()\n",
    "\n",
    "##### Read Prices Data into pandas\n",
    "filename = 'SP_500_close_2015.csv'\n",
    "priceData = pd.read_csv(filename,index_col = 0)\n",
    "\n",
    "##### Call the function to calculate stocks' daily returns from the price data\n",
    "returns = returns_Stocks (priceData)\n",
    "\n",
    "# test that manual and built-in calculations are the same\n",
    "# uncomment the next line of code to run test\n",
    "#test_returns_Stock_built_in_equals_manual(priceData)\n",
    "\n",
    "\n",
    "##### END OF PART 1 #####\n",
    "\n",
    "\n",
    "\n",
    "##### START OF PART 2 - find correlations between stocks' daily returns #####\n",
    "\n",
    "##~~ KEY VARIABLE: \"correlationTable\" stores correlation results \n",
    "\n",
    "##### Generate pairwise correlation table using panda\n",
    "def corTable(returns):\n",
    "    # this uses the built-in function. The manual calculation is as below.\n",
    "    return returns.corr()\n",
    "    \n",
    "# store correlation results (to use as input to other functions)\n",
    "correlationTable = corTable(returns) \n",
    "\n",
    "##### read company names into pd dataframe\n",
    "compData = pd.read_csv('SP_500_firms.csv', index_col = 0)\n",
    "\n",
    "##### Print correlation between company A and B\n",
    "def printCor(correlationTable, companyA, companyB):\n",
    "    corr = correlationTable.loc[companyA,companyB]\n",
    "    nameA = compData.loc[companyA,'Name']\n",
    "    nameB = compData.loc[companyB,'Name']\n",
    "    return nameA, nameB, corr\n",
    "\n",
    "##### Compare panda method and python manual method of calculating correlations\n",
    "def testCor_pairwise(correlationTable, companyA, companyB):\n",
    "    print('Panda method:')\n",
    "    print(correlationTable.loc[companyA,companyB])\n",
    "    print('Standard data structure method')\n",
    "    returns_for_manual = returns[1:len(returns)]\n",
    "    a,b = np.array(returns_for_manual.get(companyA).tolist(),dtype = float),np.array(returns_for_manual.get(companyB).tolist(),dtype = float)\n",
    "    print(np.sum((a - np.mean(a))/np.std(a)*(b - np.mean(b))/np.std(b))/(len(a)))\n",
    "\n",
    "##### The above does a pairwise correlation manually\n",
    "#     This chunk of code computes all pairwise correlations manually\n",
    "def testCor_allprices(returns):\n",
    "    # copy returns dataframe to initialise corr_matrix. Will edit the cell contents in code below.\n",
    "    corr_matrix = returns.copy()\n",
    "    col_names = list(returns.columns.values)\n",
    "    # remove index 0 of returns - it's a nan value because the first period data has no daily return\n",
    "    returns = returns[1:len(returns)]\n",
    "    for i in range(len(col_names)):\n",
    "        for j in range(i, len(col_names)):\n",
    "            companyA = col_names[i]\n",
    "            companyB = col_names[j]\n",
    "            a,b = np.array(returns.get(companyA).tolist(),dtype = float),np.array(returns.get(companyB).tolist(),dtype = float)\n",
    "            corr_matrix.ix[companyA, companyB] = (np.sum((a - np.mean(a))/np.std(a)*(b - np.mean(b))/np.std(b))/(len(a)))\n",
    "            corr_matrix.ix[companyB, companyA] = (np.sum((a - np.mean(a))/np.std(a)*(b - np.mean(b))/np.std(b))/(len(a)))\n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "##### make sure that the manual calculation is same as built-in function\n",
    "def test_correlation_Stock_built_in_equals_manual(returns):  \n",
    "    corr_built_in = corTable(returns)\n",
    "    corr_manual = testCor_allprices(returns)\n",
    "    difference = corr_built_in - corr_manual \n",
    "    print(\"The total difference between built-in and manual way of calculating correlations across stocks is:\", difference.sum().sum()) \n",
    "\n",
    "# To test if built-in and manual way of finding correlations are the same\n",
    "# Uncomment the lines below to test it. (have tested, values returned are the same. There is a very small difference 3.1778630833582955e-12, for the manual and built-in way of computing all correlations, likely due to rounding errors)\n",
    "#testCor_pairwise(correlationTable, 'GOOGL', 'FB')\n",
    "#test_correlation_Stock_built_in_equals_manual(returns)\n",
    "\n",
    "    \n",
    "##### List top and bottom correlated companies of a company   \n",
    "def top_bottom_Cor(correlationTable,company):\n",
    "    print('Finding the top and bottom correlated companies for ', company, ':')\n",
    "    print('===================================================')\n",
    "    min = correlationTable[company].sort_values()[0:5]\n",
    "    max = correlationTable[company].sort_values(ascending=False)[1:6]\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for i in min.index:\n",
    "        list1.append(compData.loc[i,'Name'])\n",
    "    for i in max.index:\n",
    "        list2.append(compData.loc[i,'Name'])\n",
    "    min.index = list1\n",
    "    max.index = list2\n",
    "    print('Bottom correlated :')\n",
    "    print('-----------------')\n",
    "    print(min)\n",
    "    print('') # break line\n",
    "    print('Top correlated:')\n",
    "    print('---------------')\n",
    "    print(max)\n",
    "\n",
    "\n",
    "##### END OF PART 2 #####\n",
    "\n",
    "\n",
    "##### START OF PART 4 part 1 - more efficient clustering algorithm #####\n",
    "\n",
    "##~~ KEY VARIABLE: nodeList stores a list of Nodes, each node representing a stock price. Find(nodeList[i]).getSet()) will return the set of nodes that belong to the same cluster as nodeList[i]\n",
    "\n",
    "##### Store all stock names into a list\n",
    "all_stock_names = list(correlationTable.columns.values)\n",
    "n = len(all_stock_names)\n",
    "\n",
    "# COMMENT: The length of namesDict and all_stock_names \n",
    "#          DO NOT MATCH! all_stock_names is correct, \n",
    "#          there are 496 stock names in the price csv file\n",
    "#          len(namesDict) shows 504, which matches \n",
    "#          the firms csv file\n",
    "#          So the results differ because of the csv files.\n",
    "#          To check that the usage of namesDict is correct.\n",
    "\n",
    "##### Add all pairwise correlation (upper-triangle matrix), into a list\n",
    "edge_list = []\n",
    "for i in range(len(all_stock_names)-1):\n",
    "    for j in range(i+1, len(all_stock_names)):\n",
    "        # add tuple (weight, source, destination) to list\n",
    "        edge_list.append( (correlationTable.loc[all_stock_names[i], all_stock_names[j]], i, j) )\n",
    "\n",
    "# sort them in descending order\n",
    "edge_list = sorted(edge_list, reverse = True)\n",
    "\n",
    "##### Create a node class with:\n",
    "#       node_name: prints the stock's name\n",
    "#       parent: nodes with the same parent will belong to the same cluster\n",
    "#       rank: depth of the node. Use this for efficient merging - tries to keep tree as balanced as possible - shorter search time\n",
    "#       setlist: stores the names of all the nodes that belong to the same cluster. Updates this when sets are merged \n",
    "#                (the root of the tree at any time will always store the complete set of nodes belonging to the same cluster)\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, node_name):\n",
    "        self.name = node_name\n",
    "        # maintain a list that stores all the nodes\n",
    "        # in the same cluster. Update this list when\n",
    "        # clusters merge (i.e. update the root node list)\n",
    "        self.setlist = [node_name];\n",
    "    \n",
    "    def setParent(self, node):\n",
    "        self.parent = node\n",
    "        \n",
    "    def getParent(self):\n",
    "        return self.parent\n",
    "        \n",
    "    def setRank(self, rank):\n",
    "        self.rank = rank\n",
    "\n",
    "    def getRank(self):\n",
    "        return self.rank\n",
    "        \n",
    "    def getSet(self):\n",
    "        return self.setlist\n",
    "        \n",
    "    def mergeSet(self, node):\n",
    "        # update the root node list whenever there is a merge operation. Root of the tree will have the complete set list\n",
    "        node.getSet().extend(self.setlist)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "\n",
    "def MakeSet(x):\n",
    "    x.setParent(x)\n",
    "    x.setRank(0)\n",
    "    \n",
    "def Union(x, y):\n",
    "    # Union in a way such that the depth of the tree is minimised\n",
    "    # always add the shorter tree under the deeper tree so that the height doesn't increase\n",
    "    xRoot = Find(x)\n",
    "    yRoot = Find(y)\n",
    "    if xRoot == yRoot:\n",
    "        return\n",
    "\n",
    "    # x and y are not already in same set. Merge them.\n",
    "    # always merge the smaller subtree into the bigger one\n",
    "    # to minimise the tree height\n",
    "    if xRoot.getRank() < yRoot.getRank():\n",
    "        xRoot.setParent(yRoot)\n",
    "        xRoot.mergeSet(yRoot)\n",
    "    elif xRoot.getRank() > yRoot.getRank():\n",
    "        yRoot.setParent(xRoot)\n",
    "        yRoot.mergeSet(xRoot)\n",
    "    else:\n",
    "        yRoot.setParent(xRoot)\n",
    "        yRoot.mergeSet(xRoot)\n",
    "        xRoot.setRank(xRoot.getRank() + 1)\n",
    "        \n",
    "def Find(x):\n",
    "    # Path compression - whenever you're finding the root of a node, set the parent to the root directly\n",
    "    if x.getParent() != x:\n",
    "        x.setParent(Find(x.getParent()))\n",
    "    return x.getParent()\n",
    "    \n",
    "def link_clusters(edge_list, node_names, k):\n",
    "    # edge_list is list of sorted edges in tuple form (weight, source, destination)\n",
    "    # node_names is the list of nodes' names\n",
    "    # k is the number of iterations\n",
    "\n",
    "    # get number of nodes\n",
    "    n = len(node_names)\n",
    "    \n",
    "    # initialise nodePointers dictionary of linked nodes\n",
    "    nodeList = []\n",
    "\n",
    "    # add all the node names as Nodes into the list and init MakeSet (each node is a set of itself at the beginning)\n",
    "    for i in range(n):\n",
    "        nodeList.append(Node(node_names[i]))\n",
    "        MakeSet(nodeList[i])        \n",
    "        \n",
    "    # loop this k times\n",
    "    for i in range(k):\n",
    "        # extract the k highest weights / correlations from the list\n",
    "        # Negative correlated nodes should be nearer to the end of the list (i.e. stocks that are dissimiliar to each other, in opposite direction)\n",
    "        # Negative weights should not affect the algorithm correctness\n",
    "        weight, source, dest = edge_list[i]\n",
    "        print(weight, source, dest) # for debugging purposes\n",
    "        Union(nodeList[source], nodeList[dest])\n",
    "        \n",
    "    return nodeList\n",
    "    \n",
    "## test with k = 6\n",
    "#nodeList = link_clusters(edge_list, all_stock_names, 99)\n",
    "\n",
    "## test result\n",
    "#for i in range(n):\n",
    "#    print(\"Node\", nodeList[i], \"is in same set as Node \", Find(nodeList[i]), \". Cluster of nodes are:\", Find(nodeList[i]).getSet())\n",
    "    \n",
    "\n",
    "##### END OF PART 4 part 1 #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "<b>Exploring other clustering methods</b>\n",
    "\n",
    "You've used just one approach to clustering, and arguably not the best one. \n",
    "\n",
    "Research clustering algorithms and libraries to apply them in Python. \n",
    "\n",
    "* {answer and/or code}\n",
    "\n",
    "Discuss some other algorithms that could be used, and how they di\u001ber from the one you've implemented. \n",
    "\n",
    "* {answer}\n",
    "\n",
    "Look at the Python library scikit-learn. How would you apply the clustering algorithms provided by the library to stock price data? \n",
    "\n",
    "* {answer}\n",
    "\n",
    "Would you need to develop new metrics other than correlations? If you want to go even further, try running some of these other clustering algorithms on your data, and report the results. Start from here: http://scikit-learn.org/stable/modules/clustering.html#clustering\n",
    "You'll fi\u001c",
    "nd a stock market example there too. For future reference, you may also \u001c",
    "nd other interesting machine-learning\n",
    "tools for both stock market analysis or other analytics purposes.\n",
    "\n",
    "* {answer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### START OF PART 4.2 (Extra Part 2) - clustering algorithm #####\n",
    "\n",
    "##~~ KEY VARIABLE: \" \" stores {} \n",
    "\n",
    "##### END OF PART 4.2 (Extra Part 2) #####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
