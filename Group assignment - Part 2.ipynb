{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "BS1819-1617  \n",
    "Data Structures and Algorithms  \n",
    "Group Assignment  \n",
    "</b>\n",
    "\n",
    "Team 3:  \n",
    "  * Ahmad Bilal Aslam  \n",
    "  * Chris Ying  \n",
    "  * Christina Lefkothea Tatli   \n",
    "  * Joh B  \n",
    "  * Kelvin Goh  \n",
    "  * Selly Salkha  \n",
    "\n",
    "\n",
    "<b><u> Part 2 </u></b>\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## PART ONE code - to remove this when merging all the Jupyter notebooks together ##\n",
    "####################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "##### START OF PART 1 - calculate daily returns #####\n",
    "\n",
    "##~~ KEY VARIABLE: \"returns\" stores daily returns of stocks\n",
    "\n",
    "##### To Read company names into a dictionary\n",
    "def readNamesIntoDict():\n",
    "    d = dict()\n",
    "    input_file = csv.DictReader(open(\"SP_500_firms.csv\"))\n",
    "    for row in input_file:\n",
    "        #print(row)\n",
    "        d[row['Symbol']] = [row['Name'],row['Sector']]\n",
    "    return d\n",
    "\n",
    "##### To calculate daily returns from stock prices\n",
    "def returns_Stocks(priceData):      \n",
    "    # input is a pd.dataframe of stock prices\n",
    "    # output is a pd.dataframe of daily returns    \n",
    "    returns = priceData.pct_change()\n",
    "    # remove index 0 of returns - it's a nan value because the first period data has no daily return\n",
    "    #returns = returns[1:len(returns)]\n",
    "    # We had used the built-in function, the next function below is the manual calculation\n",
    "    return returns\n",
    "\n",
    "def returns_Stocks_manual_calc(priceData):      \n",
    "    # Manual calculation of the returns\n",
    "    returns = priceData / priceData.shift(1) - 1\n",
    "    # remove index 0 of returns - it's a nan value because the first period data has no daily return\n",
    "    #returns = returns[1:len(returns)]\n",
    "    return returns\n",
    "\n",
    "# make sure that the manual calculation is same as built-in function\n",
    "def test_returns_Stock_built_in_equals_manual(priceData):  \n",
    "    returns_built_in = returns_Stocks(priceData)\n",
    "    returns_manual = returns_Stocks_manual_calc(priceData)\n",
    "    difference = returns_built_in - returns_manual \n",
    "    print(\"The total difference between built-in and manual way of calculating daily returns, across stocks and time period, is:\", difference.sum().sum()) \n",
    "\n",
    "##### Several functions to determine which stock has max, min return; which are overall best, worst stocks; and max and min std of daily returns\n",
    "def max_return(returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of daily returns, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the maximum daily return along with company name and Sector\n",
    "    maxDaily_byComp  = returns.max()            #Maximum returns for each company\n",
    "\n",
    "    maxDaily = maxDaily_byComp.max()            #Overall highest daily return\n",
    "    maxDaily_CompSym = maxDaily_byComp.idxmax() #Getting index of the maximum return value\n",
    "\n",
    "    maxDaily_CompName = namesDict[maxDaily_CompSym][0]  #Company Name using its symbol\n",
    "    maxDaily_Sector = namesDict[maxDaily_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return maxDaily_Sector, maxDaily_CompName, maxDaily\n",
    "    \n",
    "\n",
    "def min_return (returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of daily returns, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the minimum daily return along with company name and Sector\n",
    "\n",
    "    minDaily_byComp  = returns.min()            #Minimum returns for each company\n",
    "\n",
    "    minDaily = minDaily_byComp.min()            #Overall lowest daily return\n",
    "    minDaily_CompSym = minDaily_byComp.idxmin() #Getting index of the minimum return value\n",
    "\n",
    "    minDaily_CompName = namesDict[minDaily_CompSym][0]  #Company Name using its symbol\n",
    "    minDaily_Sector = namesDict[minDaily_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return minDaily_Sector, minDaily_CompName, minDaily\n",
    "\n",
    "\n",
    "def overall_best (priceData, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the maximum yearly return along with company name and Sector\n",
    "    overallReturn_byComp  = priceData.iloc[-1] / priceData.iloc[0] - 1   #yearly returns for each company\n",
    "\n",
    "    overallBest = overallReturn_byComp.max()            #best yearly return\n",
    "    overallBest_CompSym = overallReturn_byComp.idxmax() #Getting index of the best yearly return\n",
    "\n",
    "     #Loading Company Symbols mapping into namesDict\n",
    "    overallBest_CompName = namesDict[overallBest_CompSym][0]  #Company Name using its symbol\n",
    "    overallBest_Sector = namesDict[overallBest_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return overallBest_Sector, overallBest_CompName, overallBest\n",
    "    \n",
    "\n",
    "def overall_worst (priceData, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the minimum yearly return along with company name and Sector\n",
    "    overallReturn_byComp  = priceData.iloc[-1] / priceData.iloc[0] - 1   #yearly returns for each company\n",
    "\n",
    "    overallWorst = overallReturn_byComp.min()            #worst yearly return\n",
    "    overallWorst_CompSym = overallReturn_byComp.idxmin() #Getting index of the worst yearly return\n",
    "\n",
    "    overallWorst_CompName = namesDict[overallWorst_CompSym][0]  #Company Name using its symbol\n",
    "    overallWorst_Sector = namesDict[overallWorst_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return overallWorst_Sector, overallWorst_CompName, overallWorst\n",
    "\n",
    "\n",
    "def max_std (returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the maximum std. dev along with company name and Sector\n",
    "    std_byComp  = returns.std()            #std. dev of returns for each company\n",
    "\n",
    "    maxStd = std_byComp.max()            #maximum std. dev\n",
    "    maxStd_CompSym = std_byComp.idxmax() #Getting index of the maximum std. dev\n",
    "\n",
    "    namesDict = readNamesIntoDict() #Loading Company Symbols mapping into namesDict\n",
    "    maxStd_CompName = namesDict[maxStd_CompSym][0]  #Company Name using its symbol\n",
    "    maxStd_Sector = namesDict[maxStd_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return maxStd_Sector, maxStd_CompName, maxStd\n",
    "    \n",
    "    \n",
    "def min_std (returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the minimum std. dev along with company name and Sector\n",
    "    std_byComp  = returns.std()            #std. dev of returns for each company\n",
    "\n",
    "    minStd = std_byComp.min()            #minimum std. dev\n",
    "    minStd_CompSym = std_byComp.idxmin() #Getting index of the minimum std. dev\n",
    "\n",
    "    minStd_CompName = namesDict[minStd_CompSym][0]  #Company Name using its symbol\n",
    "    minStd_Sector = namesDict[minStd_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return minStd_Sector, minStd_CompName, minStd\n",
    "\n",
    "\n",
    "##### Read company names into a dictionary\n",
    "namesDict = readNamesIntoDict()\n",
    "\n",
    "##### Read Prices Data into pandas\n",
    "filename = 'SP_500_close_2015.csv'\n",
    "priceData = pd.read_csv(filename,index_col = 0)\n",
    "\n",
    "##### Call the function to calculate stocks' daily returns from the price data\n",
    "returns = returns_Stocks (priceData)\n",
    "\n",
    "# test that manual and built-in calculations are the same\n",
    "# uncomment the next line of code to run test\n",
    "#test_returns_Stock_built_in_equals_manual(priceData)\n",
    "\n",
    "\n",
    "##### END OF PART 1 #####\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "<b>Correlations</b>\n",
    "\n",
    "i. Calculate the correlations between all stocks in the data using returns. \n",
    "\n",
    "* Please refer to the corTable function in the cell below. We have used pandas built-in function, but have also coded testCor_allprices to compute it manually. The function test_correlation_Stock_built_in_equals_manual compares the results from the manual and built-in functions, and the sum of differences between both methods, across each correlation, is minute (3.1778630833582955e-12) <- likely due to rounding errors in data type conversions (e.g. for manual calculation, we had converted to Numpy arrays)\n",
    "\n",
    "ii. Provide a convenient way for a user to print out two companies' full names and a correlation between their returns using your data. \n",
    "\n",
    "* Please refer to the printCor function in the cell below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### START OF PART 2 - find correlations between stocks' daily returns #####\n",
    "\n",
    "##~~ KEY VARIABLE: \"correlationTable\" stores correlation results \n",
    "\n",
    "##### Generate pairwise correlation table using panda\n",
    "def corTable(returns):\n",
    "    # this uses the built-in function. The manual calculation is as below.\n",
    "    return returns.corr()\n",
    "    \n",
    "# store correlation results (to use as input to other functions)\n",
    "correlationTable = corTable(returns) \n",
    "\n",
    "##### read company names into pd dataframe\n",
    "compData = pd.read_csv('SP_500_firms.csv', index_col = 0)\n",
    "\n",
    "##### Print correlation between company A and B\n",
    "def printCor(correlationTable, companyA, companyB):\n",
    "    corr = correlationTable.loc[companyA,companyB]\n",
    "    nameA = compData.loc[companyA,'Name']\n",
    "    nameB = compData.loc[companyB,'Name']\n",
    "    return nameA, nameB, corr\n",
    "\n",
    "##### Compare panda method and python manual method of calculating correlations\n",
    "def testCor_pairwise(correlationTable, companyA, companyB):\n",
    "    print('Panda method:')\n",
    "    print(correlationTable.loc[companyA,companyB])\n",
    "    print('Standard data structure method')\n",
    "    returns_for_manual = returns[1:len(returns)]\n",
    "    a,b = np.array(returns_for_manual.get(companyA).tolist(),dtype = float),np.array(returns_for_manual.get(companyB).tolist(),dtype = float)\n",
    "    print(np.sum((a - np.mean(a))/np.std(a)*(b - np.mean(b))/np.std(b))/(len(a)))\n",
    "\n",
    "##### The above does a pairwise correlation manually\n",
    "#     This chunk of code computes all pairwise correlations manually\n",
    "def testCor_allprices(returns):\n",
    "    # copy returns dataframe to initialise corr_matrix. Will edit the cell contents in code below.\n",
    "    corr_matrix = returns.copy()\n",
    "    col_names = list(returns.columns.values)\n",
    "    # remove index 0 of returns - it's a nan value because the first period data has no daily return\n",
    "    returns = returns[1:len(returns)]\n",
    "    for i in range(len(col_names)):\n",
    "        for j in range(i, len(col_names)):\n",
    "            companyA = col_names[i]\n",
    "            companyB = col_names[j]\n",
    "            a,b = np.array(returns.get(companyA).tolist(),dtype = float),np.array(returns.get(companyB).tolist(),dtype = float)\n",
    "            corr_matrix.ix[companyA, companyB] = (np.sum((a - np.mean(a))/np.std(a)*(b - np.mean(b))/np.std(b))/(len(a)))\n",
    "            corr_matrix.ix[companyB, companyA] = (np.sum((a - np.mean(a))/np.std(a)*(b - np.mean(b))/np.std(b))/(len(a)))\n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "##### make sure that the manual calculation is same as built-in function\n",
    "def test_correlation_Stock_built_in_equals_manual(returns):  \n",
    "    corr_built_in = corTable(returns)\n",
    "    corr_manual = testCor_allprices(returns)\n",
    "    difference = corr_built_in - corr_manual \n",
    "    print(\"The total difference between built-in and manual way of calculating correlations across stocks is:\", difference.sum().sum()) \n",
    "\n",
    "# To test if built-in and manual way of finding correlations are the same\n",
    "# Uncomment the lines below to test it. (have tested, values returned are the same. There is a very small difference 3.1778630833582955e-12, for the manual and built-in way of computing all correlations, likely due to rounding errors)\n",
    "#testCor_pairwise(correlationTable, 'GOOGL', 'FB')\n",
    "#test_correlation_Stock_built_in_equals_manual(returns)\n",
    "\n",
    "    \n",
    "##### List top and bottom correlated companies of a company   \n",
    "def top_bottom_Cor(correlationTable,company):\n",
    "    print('Finding the top and bottom correlated companies for ', company, ':')\n",
    "    print('===================================================')\n",
    "    min = correlationTable[company].sort_values()[0:5]\n",
    "    max = correlationTable[company].sort_values(ascending=False)[1:6]\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for i in min.index:\n",
    "        list1.append(compData.loc[i,'Name'])\n",
    "    for i in max.index:\n",
    "        list2.append(compData.loc[i,'Name'])\n",
    "    min.index = list1\n",
    "    max.index = list2\n",
    "    print('Bottom correlated :')\n",
    "    print('-----------------')\n",
    "    print(min)\n",
    "    print('') # break line\n",
    "    print('Top correlated:')\n",
    "    print('---------------')\n",
    "    print(max)\n",
    "\n",
    "\n",
    "##### END OF PART 2 #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the printCor function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Alphabet Inc Class A', 'Facebook', 0.58654766625005228)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printCor(correlationTable, \"GOOGL\", \"FB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Also provide a convenient way to print out the top and bottom correlated companies for any given company. \n",
    "\n",
    "* Please refer to the top_bottom_Cor function in the code cells above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Use this to comment on the following companies in the tech sector: Amazon, Microsoft, Facebook, Apple, and Google \n",
    "Which companies are they most closely related to in terms of highest correlations? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the top and bottom correlated companies for  AAPL :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Range Resources Corp.               0.112711\n",
      "Chipotle Mexican Grill              0.130501\n",
      "Newmont Mining Corp. (Hldg. Co.)    0.143713\n",
      "Transocean                          0.144045\n",
      "Southwestern Energy                 0.146811\n",
      "Name: AAPL, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Illinois Tool Works       0.601265\n",
      "Northrop Grumman Corp.    0.589368\n",
      "Honeywell Int'l Inc.      0.576730\n",
      "Fiserv Inc                0.573935\n",
      "Skyworks Solutions        0.573350\n",
      "Name: AAPL, dtype: float64\n",
      "\n",
      "Finding the top and bottom correlated companies for  AMZN :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Stericycle Inc         0.056451\n",
      "Transocean             0.060162\n",
      "Southwestern Energy    0.082376\n",
      "TripAdvisor            0.087684\n",
      "Whole Foods Market     0.090700\n",
      "Name: AMZN, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Alphabet Inc Class A    0.585553\n",
      "Alphabet Inc Class C    0.584337\n",
      "Starbucks Corp.         0.571951\n",
      "Visa Inc.               0.560704\n",
      "Mastercard Inc.         0.538708\n",
      "Name: AMZN, dtype: float64\n",
      "\n",
      "Finding the top and bottom correlated companies for  MSFT :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Stericycle Inc         0.028887\n",
      "NRG Energy             0.090761\n",
      "Transocean             0.113785\n",
      "Southwestern Energy    0.114787\n",
      "Urban Outfitters       0.128788\n",
      "Name: MSFT, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Marsh & McLennan             0.604549\n",
      "Procter & Gamble             0.604204\n",
      "Mastercard Inc.              0.590886\n",
      "Automatic Data Processing    0.589445\n",
      "Starbucks Corp.              0.583705\n",
      "Name: MSFT, dtype: float64\n",
      "\n",
      "Finding the top and bottom correlated companies for  FB :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Newmont Mining Corp. (Hldg. Co.)   -0.002832\n",
      "Transocean                          0.013327\n",
      "Southwestern Energy                 0.047667\n",
      "Diamond Offshore Drilling           0.054310\n",
      "Chesapeake Energy                   0.058682\n",
      "Name: FB, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Fiserv Inc               0.619667\n",
      "Mastercard Inc.          0.617659\n",
      "Starbucks Corp.          0.598190\n",
      "Alphabet Inc Class A     0.586548\n",
      "Total System Services    0.580214\n",
      "Name: FB, dtype: float64\n",
      "\n",
      "Finding the top and bottom correlated companies for  GOOGL :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Transocean                   0.009523\n",
      "Range Resources Corp.        0.043924\n",
      "Diamond Offshore Drilling    0.045733\n",
      "Southwestern Energy          0.062425\n",
      "Stericycle Inc               0.062576\n",
      "Name: GOOGL, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Alphabet Inc Class C    0.989365\n",
      "Facebook                0.586548\n",
      "Amazon.com Inc          0.585553\n",
      "Progressive Corp.       0.556862\n",
      "Mastercard Inc.         0.515583\n",
      "Name: GOOGL, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_bottom_Cor(correlationTable,'AAPL')\n",
    "print(\"\") # break line\n",
    "top_bottom_Cor(correlationTable,'AMZN')\n",
    "print(\"\") # break line\n",
    "top_bottom_Cor(correlationTable,'MSFT')\n",
    "print(\"\") # break line\n",
    "top_bottom_Cor(correlationTable,'FB')\n",
    "print(\"\") # break line\n",
    "top_bottom_Cor(correlationTable,'GOOGL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Would you have expected the results you see?\n",
    "\n",
    "* {to fill in}\n",
    "* e.g. Apple's top correlated stocks are not in the tech sector.. surprising? They don't seem to be Apple's suppliers either.\n",
    "* e.g. Top correlated stocks with Amazon are not surprising - Visa / Mastercard's revenues will likely depend on the revenues of Amazon which is an e-commerce website (i.e. Amazon's clients will likely make purchases via Visa or Mastercard debit/credit cards).\n",
    "* e.g. comment on bottom correlated stocks as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
