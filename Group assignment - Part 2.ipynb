{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will calculate the correlations between all stocks using returns calculated in part 1. We will also write functions that allow users to conveniently:\n",
    "- print out correlations between two companies \n",
    "- print out top and bottom correlated companies of a specified company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PART ONE code - to remove this when merging all the Jupyter notebooks together ##\n",
    "####################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "##### START OF PART 1 - calculate daily returns #####\n",
    "\n",
    "##~~ KEY VARIABLE: \"returns\" stores daily returns of stocks\n",
    "\n",
    "##### To Read company names into a dictionary\n",
    "def readNamesIntoDict():\n",
    "    d = dict()\n",
    "    input_file = csv.DictReader(open(\"SP_500_firms.csv\"))\n",
    "    for row in input_file:\n",
    "        #print(row)\n",
    "        d[row['Symbol']] = [row['Name'],row['Sector']]\n",
    "    return d\n",
    "\n",
    "##### To calculate daily returns from stock prices\n",
    "def returns_Stocks(priceData):      \n",
    "    # input is a pd.dataframe of stock prices\n",
    "    # output is a pd.dataframe of daily returns    \n",
    "    returns = priceData.pct_change()\n",
    "    # remove index 0 of returns - it's a nan value because the first period data has no daily return\n",
    "    #returns = returns[1:len(returns)]\n",
    "    # We had used the built-in function, the next function below is the manual calculation\n",
    "    return returns\n",
    "\n",
    "def returns_Stocks_manual_calc(priceData):      \n",
    "    # Manual calculation of the returns\n",
    "    returns = priceData / priceData.shift(1) - 1\n",
    "    # remove index 0 of returns - it's a nan value because the first period data has no daily return\n",
    "    #returns = returns[1:len(returns)]\n",
    "    return returns\n",
    "\n",
    "# make sure that the manual calculation is same as built-in function\n",
    "def test_returns_Stock_built_in_equals_manual(priceData):  \n",
    "    returns_built_in = returns_Stocks(priceData)\n",
    "    returns_manual = returns_Stocks_manual_calc(priceData)\n",
    "    difference = returns_built_in - returns_manual \n",
    "    print(\"The total difference between built-in and manual way of calculating daily returns, across stocks and time period, is:\", difference.sum().sum()) \n",
    "\n",
    "##### Several functions to determine which stock has max, min return; which are overall best, worst stocks; and max and min std of daily returns\n",
    "def max_return(returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of daily returns, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the maximum daily return along with company name and Sector\n",
    "    maxDaily_byComp  = returns.max()            #Maximum returns for each company\n",
    "\n",
    "    maxDaily = maxDaily_byComp.max()            #Overall highest daily return\n",
    "    maxDaily_CompSym = maxDaily_byComp.idxmax() #Getting index of the maximum return value\n",
    "\n",
    "    maxDaily_CompName = namesDict[maxDaily_CompSym][0]  #Company Name using its symbol\n",
    "    maxDaily_Sector = namesDict[maxDaily_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return maxDaily_Sector, maxDaily_CompName, maxDaily\n",
    "    \n",
    "\n",
    "def min_return (returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of daily returns, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the minimum daily return along with company name and Sector\n",
    "\n",
    "    minDaily_byComp  = returns.min()            #Minimum returns for each company\n",
    "\n",
    "    minDaily = minDaily_byComp.min()            #Overall lowest daily return\n",
    "    minDaily_CompSym = minDaily_byComp.idxmin() #Getting index of the minimum return value\n",
    "\n",
    "    minDaily_CompName = namesDict[minDaily_CompSym][0]  #Company Name using its symbol\n",
    "    minDaily_Sector = namesDict[minDaily_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return minDaily_Sector, minDaily_CompName, minDaily\n",
    "\n",
    "\n",
    "def overall_best (priceData, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the maximum yearly return along with company name and Sector\n",
    "    overallReturn_byComp  = priceData.iloc[-1] / priceData.iloc[0] - 1   #yearly returns for each company\n",
    "\n",
    "    overallBest = overallReturn_byComp.max()            #best yearly return\n",
    "    overallBest_CompSym = overallReturn_byComp.idxmax() #Getting index of the best yearly return\n",
    "\n",
    "     #Loading Company Symbols mapping into namesDict\n",
    "    overallBest_CompName = namesDict[overallBest_CompSym][0]  #Company Name using its symbol\n",
    "    overallBest_Sector = namesDict[overallBest_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return overallBest_Sector, overallBest_CompName, overallBest\n",
    "    \n",
    "\n",
    "def overall_worst (priceData, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the minimum yearly return along with company name and Sector\n",
    "    overallReturn_byComp  = priceData.iloc[-1] / priceData.iloc[0] - 1   #yearly returns for each company\n",
    "\n",
    "    overallWorst = overallReturn_byComp.min()            #worst yearly return\n",
    "    overallWorst_CompSym = overallReturn_byComp.idxmin() #Getting index of the worst yearly return\n",
    "\n",
    "    overallWorst_CompName = namesDict[overallWorst_CompSym][0]  #Company Name using its symbol\n",
    "    overallWorst_Sector = namesDict[overallWorst_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return overallWorst_Sector, overallWorst_CompName, overallWorst\n",
    "\n",
    "\n",
    "def max_std (returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the maximum std. dev along with company name and Sector\n",
    "    std_byComp  = returns.std()            #std. dev of returns for each company\n",
    "\n",
    "    maxStd = std_byComp.max()            #maximum std. dev\n",
    "    maxStd_CompSym = std_byComp.idxmax() #Getting index of the maximum std. dev\n",
    "\n",
    "    namesDict = readNamesIntoDict() #Loading Company Symbols mapping into namesDict\n",
    "    maxStd_CompName = namesDict[maxStd_CompSym][0]  #Company Name using its symbol\n",
    "    maxStd_Sector = namesDict[maxStd_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return maxStd_Sector, maxStd_CompName, maxStd\n",
    "    \n",
    "    \n",
    "def min_std (returns, namesDict = readNamesIntoDict()):    \n",
    "    # input: pd.dataframe of price data, and a dictionary of company/sector (call the readNamesIntoDict() function if the dictionary is not passed as an argument)\n",
    "    # output: returns the minimum std. dev along with company name and Sector\n",
    "    std_byComp  = returns.std()            #std. dev of returns for each company\n",
    "\n",
    "    minStd = std_byComp.min()            #minimum std. dev\n",
    "    minStd_CompSym = std_byComp.idxmin() #Getting index of the minimum std. dev\n",
    "\n",
    "    minStd_CompName = namesDict[minStd_CompSym][0]  #Company Name using its symbol\n",
    "    minStd_Sector = namesDict[minStd_CompSym][1]    #Company Sector\n",
    "    \n",
    "    return minStd_Sector, minStd_CompName, minStd\n",
    "\n",
    "\n",
    "##### Read company names into a dictionary\n",
    "namesDict = readNamesIntoDict()\n",
    "\n",
    "##### Read Prices Data into pandas\n",
    "filename = 'SP_500_close_2015.csv'\n",
    "priceData = pd.read_csv(filename,index_col = 0)\n",
    "\n",
    "##### Call the function to calculate stocks' daily returns from the price data\n",
    "returns = returns_Stocks (priceData)\n",
    "\n",
    "# test that manual and built-in calculations are the same\n",
    "# uncomment the next line of code to run test\n",
    "#test_returns_Stock_built_in_equals_manual(priceData)\n",
    "\n",
    "\n",
    "##### END OF PART 1 #####\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation dataframe using panda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we calcuated the correlations between companies using the built-in function pd.corr() in the Panda library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corTable(returns):\n",
    "    # Input: a panda dataframe consisting the returns of all the stocks\n",
    "    # Output: a symmetric panda dataframe with correlations between all companies\n",
    "    # this uses the built-in function. The manual calculation is as below.\n",
    "    return returns.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this corTable function we can now create our correlationTable using returns from part 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store correlation results (to use as input for other functions)\n",
    "correlationTable = corTable(returns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking panda results with direct calculation from definition using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check that the Panda built-in functions has done its job accurately, we created a function to calculate the correlation manually from definition and compare with the number obtained from panda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need a panda dataframe that fetch company full name from its abbreviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compData = pd.read_csv('SP_500_firms.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function to check if panda correlation results are same as calculating manually. \n",
    "The function test_correlation_Stock_built_in_equals_manual compares the results from the manual and built-in functions, and the sum of differences between both methods, across each correlation, is minute (3.1778630833582955e-12) <- likely due to rounding errors in data type conversions (e.g. for manual calculation, we had converted to Numpy arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Compare panda method and python manual method of calculating correlations\n",
    "def testCor_pairwise(correlationTable, companyA, companyB):\n",
    "    print('Panda method:')\n",
    "    print(correlationTable.loc[companyA,companyB])\n",
    "    print('Standard data structure method')\n",
    "    # remove the first element of returns as it is nan. if not removed, np.mean will return nan.\n",
    "    returns_for_manual = returns[1:len(returns)]\n",
    "    a,b = np.array(returns_for_manual.get(companyA).tolist(),dtype = float),np.array(returns_for_manual.get(companyB).tolist(),dtype = float)\n",
    "    print(np.sum((a - np.mean(a))/np.std(a)*(b - np.mean(b))/np.std(b))/(len(a)))\n",
    "    \n",
    "##### The above does a pairwise correlation manually\n",
    "#     This chunk of code computes all pairwise correlations manually\n",
    "def testCor_allprices(returns):\n",
    "    # copy returns dataframe to initialise corr_matrix. Will edit the cell contents in code below.\n",
    "    corr_matrix = returns.copy()\n",
    "    col_names = list(returns.columns.values)\n",
    "    # remove index 0 of returns - it's a nan value because the first period data has no daily return\n",
    "    returns = returns[1:len(returns)]\n",
    "    for i in range(len(col_names)):\n",
    "        for j in range(i, len(col_names)):\n",
    "            companyA = col_names[i]\n",
    "            companyB = col_names[j]\n",
    "            a,b = np.array(returns.get(companyA).tolist(),dtype = float),np.array(returns.get(companyB).tolist(),dtype = float)\n",
    "            corr_matrix.ix[companyA, companyB] = (np.sum((a - np.mean(a))/np.std(a)*(b - np.mean(b))/np.std(b))/(len(a)))\n",
    "            corr_matrix.ix[companyB, companyA] = (np.sum((a - np.mean(a))/np.std(a)*(b - np.mean(b))/np.std(b))/(len(a)))\n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "##### make sure that the manual calculation is same as built-in function\n",
    "def test_correlation_Stock_built_in_equals_manual(returns):  \n",
    "    corr_built_in = corTable(returns)\n",
    "    corr_manual = testCor_allprices(returns)\n",
    "    difference = corr_built_in - corr_manual \n",
    "    print(\"The total difference between built-in and manual way of calculating correlations across stocks is:\", difference.sum().sum()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we wish to test the correlation between Google and Facebook is calculated correctly, we would run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panda method:\n",
      "0.58654766625\n",
      "Standard data structure method\n",
      "0.58654766625\n"
     ]
    }
   ],
   "source": [
    "# To test if built-in and manual way of finding correlations are the same\n",
    "testCor_pairwise(correlationTable, 'GOOGL', 'FB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing correlation between two companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function we created to print the correlation between two specified companies by fetching the corresponding entry in the correlationTable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Print correlation between company A and B\n",
    "def printCor(correlationTable, companyA, companyB):\n",
    "    corr = correlationTable.loc[companyA,companyB]\n",
    "    nameA = compData.loc[companyA,'Name']\n",
    "    nameB = compData.loc[companyB,'Name']\n",
    "    return nameA, nameB, corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we wish to print the correlation between Amazon and Facebook, then we would:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Facebook', 'Amazon.com Inc', 0.50022154580192624)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printCor(correlationTable, 'FB', 'AMZN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing top and bottom correlated companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function we created to print the top and bottom (most positively and negatively correlated) companies of a specified company. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### List top and bottom correlated companies of a company   \n",
    "def top_bottom_Cor(correlationTable,company):\n",
    "    print('Finding the top and bottom correlated companies for ', company, ':')\n",
    "    print('===================================================')\n",
    "    min = correlationTable[company].sort_values()[0:5]\n",
    "    max = correlationTable[company].sort_values(ascending=False)[1:6]\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for i in min.index:\n",
    "        list1.append(compData.loc[i,'Name'])\n",
    "    for i in max.index:\n",
    "        list2.append(compData.loc[i,'Name'])\n",
    "    min.index = list1\n",
    "    max.index = list2\n",
    "    print('Bottom correlated :')\n",
    "    print('-----------------')\n",
    "    print(min)\n",
    "    print('') # break line\n",
    "    print('Top correlated:')\n",
    "    print('---------------')\n",
    "    print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then used the function top_bottom_Cor to find the top and bottom correlated companies of Apple, Amazon, Google, Facebook and Microsoft. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the top and bottom correlated companies for  AAPL :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Range Resources Corp.               0.112711\n",
      "Chipotle Mexican Grill              0.130501\n",
      "Newmont Mining Corp. (Hldg. Co.)    0.143713\n",
      "Transocean                          0.144045\n",
      "Southwestern Energy                 0.146811\n",
      "Name: AAPL, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Illinois Tool Works       0.601265\n",
      "Northrop Grumman Corp.    0.589368\n",
      "Honeywell Int'l Inc.      0.576730\n",
      "Fiserv Inc                0.573935\n",
      "Skyworks Solutions        0.573350\n",
      "Name: AAPL, dtype: float64\n",
      "\n",
      "Finding the top and bottom correlated companies for  AMZN :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Stericycle Inc         0.056451\n",
      "Transocean             0.060162\n",
      "Southwestern Energy    0.082376\n",
      "TripAdvisor            0.087684\n",
      "Whole Foods Market     0.090700\n",
      "Name: AMZN, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Alphabet Inc Class A    0.585553\n",
      "Alphabet Inc Class C    0.584337\n",
      "Starbucks Corp.         0.571951\n",
      "Visa Inc.               0.560704\n",
      "Mastercard Inc.         0.538708\n",
      "Name: AMZN, dtype: float64\n",
      "\n",
      "Finding the top and bottom correlated companies for  MSFT :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Stericycle Inc         0.028887\n",
      "NRG Energy             0.090761\n",
      "Transocean             0.113785\n",
      "Southwestern Energy    0.114787\n",
      "Urban Outfitters       0.128788\n",
      "Name: MSFT, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Marsh & McLennan             0.604549\n",
      "Procter & Gamble             0.604204\n",
      "Mastercard Inc.              0.590886\n",
      "Automatic Data Processing    0.589445\n",
      "Starbucks Corp.              0.583705\n",
      "Name: MSFT, dtype: float64\n",
      "\n",
      "Finding the top and bottom correlated companies for  FB :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Newmont Mining Corp. (Hldg. Co.)   -0.002832\n",
      "Transocean                          0.013327\n",
      "Southwestern Energy                 0.047667\n",
      "Diamond Offshore Drilling           0.054310\n",
      "Chesapeake Energy                   0.058682\n",
      "Name: FB, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Fiserv Inc               0.619667\n",
      "Mastercard Inc.          0.617659\n",
      "Starbucks Corp.          0.598190\n",
      "Alphabet Inc Class A     0.586548\n",
      "Total System Services    0.580214\n",
      "Name: FB, dtype: float64\n",
      "\n",
      "Finding the top and bottom correlated companies for  GOOGL :\n",
      "===================================================\n",
      "Bottom correlated :\n",
      "-----------------\n",
      "Transocean                   0.009523\n",
      "Range Resources Corp.        0.043924\n",
      "Diamond Offshore Drilling    0.045733\n",
      "Southwestern Energy          0.062425\n",
      "Stericycle Inc               0.062576\n",
      "Name: GOOGL, dtype: float64\n",
      "\n",
      "Top correlated:\n",
      "---------------\n",
      "Alphabet Inc Class C    0.989365\n",
      "Facebook                0.586548\n",
      "Amazon.com Inc          0.585553\n",
      "Progressive Corp.       0.556862\n",
      "Mastercard Inc.         0.515583\n",
      "Name: GOOGL, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_bottom_Cor(correlationTable,'AAPL')\n",
    "print(\"\") # break line\n",
    "top_bottom_Cor(correlationTable,'AMZN')\n",
    "print(\"\") # break line\n",
    "top_bottom_Cor(correlationTable,'MSFT')\n",
    "print(\"\") # break line\n",
    "top_bottom_Cor(correlationTable,'FB')\n",
    "print(\"\") # break line\n",
    "top_bottom_Cor(correlationTable,'GOOGL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the above results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some interesting results and some are expected:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google:\n",
    "- Its very high positive correlation with Alphabet Inc is expected since Alphabet is the parent company of Google. If the value of Google goes up the value of Alphabet Inc is likely to good up, and vice versa. \n",
    "- Its high positive correlation with giant tech companies such as Facebook and Amazon is also expected since they are very similar companies and hence would perform similarly in the same market conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook:\n",
    "- Its high positive correlation with Mastercard and Fiserv (both technological financial service companies) is expected because Facebook is a platform that help advertising and attracting people shop pay and shop online and hence helping these companies to expand their businesses. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon:\n",
    "- Its positive correlation with Alphabet is expected due to the similar type of companies they are. Tech companies are likely to do similarly over time under the same market conditions\n",
    "- Its positive correlation with Mastercard and Visa is expected because they are the two most popular ways to pay online and hence Visa and Mastercard would benefit form good performance of Amazon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple: \n",
    "- Skywork and Illinois Tool Works are electronic component manufacturers (especially Skywork where they make wireless handset chips) and perhaps Apple manufacture products which require chips and components from these companies and hence their stock performance would be correlated; when Apple announces a new product, causing its value to rise, these electronic components manufacturer is likely to make a lot of money through selling components to Apple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
